#####1ï¼šæ‰¹é‡æ•°æ®ä¸‹è½½######

#æ·»åŠ ç¯å¢ƒ
export PATH=/data/gaoyunyun/sratoolkit.3.1.1-ubuntu64/bin:$PATH
#è¿è¡Œè„šæœ¬
SRR_download.sh





########2-Aï¼šè´¨æ§########

######Step 1: è´¨æ§ï¼Œç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„è´¨æ§æŠ¥å‘Šï¼ˆHTMLæ ¼å¼ï¼‰########
#è¾“å…¥æ–‡ä»¶ï¼š/download/SRA_seq/{}_1.fastq.gz  /download/SRA_seq/{}_2.fastq.gz     ä¸‹è½½çš„åŸå§‹åŒç«¯æµ‹åºç»“æœ
#è¾“å‡ºæ–‡ä»¶ï¼štemp/qc/{}_1.fastq.gz    temp/qc/{}_2.fastq.gz    è´¨æ§åçš„åŒç«¯åºåˆ—
          temp/qc/{}_fastp.json    temp/qc/{}_fastp.html     è¾“å‡ºæ¯ä¸ªæ ·æœ¬è´¨æ§çš„ .json å’Œ .html æŠ¥å‘Š
          fastp.txt     ç»Ÿè®¡æ¯ä¸ªæ ·æœ¬çš„åŸå§‹ reads æ•°é‡å’Œæ¸…æ´—åçš„ reads æ•°é‡ï¼Œå¹¶æŒ‰ metadata.txt é¡ºåºè¾“å‡º

# åˆ›å»ºç”¨äºä¸´æ—¶å­˜å‚¨å’Œæœ€ç»ˆç»“æœè¾“å‡ºçš„æ–‡ä»¶å¤¹
    mkdir -p temp/qc result/qc
    fastp
 
# å¤šæ ·æœ¬å¹¶è¡Œè´¨æ§
# -j 2: è¡¨ç¤ºåŒæ—¶å¤„ç†2ä¸ªæ ·æœ¬ï¼›j3,18s,8m; ç›®å‰6ä¸ªæ ·æœ¬j2, 2m4.247s
#ä» metadata.txt æå–æ ·æœ¬ IDã€‚
#åˆ©ç”¨parallel å¹¶è¡Œè¿è¡Œ fastpï¼š
#--bar è§‚å¯Ÿä»»åŠ¡è¿›åº¦
#-j å’Œ -h è¾“å‡ºæ¯ä¸ªæ ·æœ¬çš„ .json å’Œ .html æŠ¥å‘Šã€‚
#-o å’Œ -O åˆ†åˆ«è¾“å‡º clean çš„ R1 å’Œ R2å‹ç¼©æ ¼å¼ï¼ˆ.fastq.gzï¼‰
#--compression 6 ä¿è¯è¾“å‡ºæ˜¯ gzip å‹ç¼©æ–‡ä»¶
#> log 2>&1 è®°å½•æ—¥å¿—ä¾›åç»­ç»Ÿè®¡ä½¿ç”¨ã€‚

time tail -n+2 result/metadata.txt | cut -f1 | parallel -j 2 --bar \
"fastp -i /data/gaoyunyun/project/anmiaomiao/download/SRA_seq/{}_1.fastq.gz \
 -I /data/gaoyunyun/project/anmiaomiao/download/SRA_seq/{}_2.fastq.gz \
 -j temp/qc/{}_fastp.json -h temp/qc/{}_fastp.html \
 -o temp/qc/{}_1.fastq.gz -O temp/qc/{}_2.fastq.gz \
 --compression 6 \
 > temp/qc/{}.log 2>&1"

# è´¨æ§åç»“æœæ±‡æ€»ï¼šç»Ÿè®¡æ¯ä¸ªæ ·æœ¬çš„åŸå§‹ reads æ•°é‡å’Œæ¸…æ´—åçš„ reads æ•°é‡ï¼Œå¹¶æŒ‰ metadata.txt é¡ºåºè¾“å‡ºæ–‡ä»¶fastp.txtï¼ŒåŒ…å«ä¸‰åˆ—SampleIDï¼›Rawï¼›Clean
# åˆ›å»ºä¸€ä¸ªä¸´æ—¶è¾“å‡ºæ–‡ä»¶ï¼Œå¹¶å†™å…¥è¡¨å¤´
# éå† metadata ä¸­æ¯ä¸ªæ ·æœ¬çš„æ ·æœ¬åï¼ˆè·³è¿‡è¡¨å¤´ï¼‰

echo -e "SampleID\tRaw\tClean" > temp/fastp
for i in `tail -n+2 result/metadata.txt | cut -f1`; do
    echo -e -n "$i\t" >> temp/fastp
    grep 'total reads' temp/qc/${i}.log | uniq | cut -f2 -d ':' | tr '\n' '\t' >> temp/fastp
    echo "" >> temp/fastp
done
sed -i 's/ //g;s/\t$//' temp/fastp

# æ ¹æ® metadata æ–‡ä»¶çš„é¡ºåºé‡æ–°æ’åº fastp.txt
head -1 temp/fastp > result/qc/fastp.txt   # å†™å…¥è¡¨å¤´
awk 'NR==FNR && FNR>1 {a[$1]=$0; next} FNR>1 {print a[$1]}' temp/fastp result/metadata.txt >> result/qc/fastp.txt

# æŸ¥çœ‹ç»“æœ
cat result/qc/fastp.txt

########Step 2: æ ¹æ®qcç»“æœï¼Œç»Ÿè®¡æ˜¯å¦ç¬¦åˆè´¨æ§è¦æ±‚########

#è¾“å…¥æ–‡ä»¶ï¼štemp/qc/{}_fastp.json    Fastp ç”Ÿæˆçš„ JSON è´¨é‡æ§åˆ¶æŠ¥å‘Š
#è¾“å‡ºæ–‡ä»¶ï¼šqc_summary.tsv   è§£æ Fastp ç”Ÿæˆçš„ JSON è´¨é‡æ§åˆ¶æŠ¥å‘Šï¼Œæ±‡æ€»çš„è¡¨æ ¼ ï¼Œæ¥åˆ¤æ–­æ¯ä¸ªæ ·æœ¬æ˜¯å¦é€šè¿‡äº† QCï¼ˆè´¨é‡æ§åˆ¶ï¼‰æ ‡å‡†

#Python è„šæœ¬ï¼ˆfastp_qc_summary.pyï¼‰ç”¨äºè§£æ Fastp ç”Ÿæˆçš„ JSON è´¨é‡æ§åˆ¶æŠ¥å‘Šï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ±‡æ€»è¡¨ qc_summary.tsvï¼Œæ¥åˆ¤æ–­æ¯ä¸ªæ ·æœ¬æ˜¯å¦é€šè¿‡äº† QCï¼ˆè´¨é‡æ§åˆ¶ï¼‰æ ‡å‡†ã€‚
# è¾“å…¥æ–‡ä»¶ï¼š
#ä½äºç›®å½•ï¼štemp/qc/
#æ–‡ä»¶æ ¼å¼ï¼šä»¥ _fastp.json ç»“å°¾çš„ JSON æ–‡ä»¶
#è¿™äº›æ–‡ä»¶æ˜¯ç”± Fastp å·¥å…·ç”Ÿæˆçš„è´¨é‡æ§åˆ¶æŠ¥å‘Šï¼Œé€šå¸¸ç”¨äºæµ‹åºæ•°æ®ï¼ˆå¦‚ FASTQ æ–‡ä»¶ï¼‰çš„è´¨é‡è¯„ä¼°ã€‚

#ä¾æ®æ–‡çŒ®ï¼šä¸­ååŒ»å­¦ä¼šæ£€éªŒåŒ»å­¦åˆ†ä¼š. ç—…åŸå¾®ç”Ÿç‰©å®åŸºå› ç»„æµ‹åºç”Ÿç‰©ä¿¡æ¯åˆ†æåŠæŠ¥å‘Šè´¨é‡æ§åˆ¶ä¸“å®¶å…±è¯†[J]. ä¸­åæ£€éªŒåŒ»å­¦æ‚å¿—, 2025, 48(1): 28-37. 
#é€‰æ‹©QC åˆ¤æ–­æ ‡å‡†å¦‚ä¸‹ï¼š
#Q20 è´¨é‡å¾—åˆ†ç‡	â‰¥ 0.95
#Q30 è´¨é‡å¾—åˆ†ç‡	â‰¥ 0.85
#Reads	â‰¥ 10,000,000
#ä¿ç•™ç‡ï¼ˆæ¸…æ´—/åŸå§‹ï¼‰	â‰¥ 0.80
#å»æ¥å¤´è¯»æ•° > 0	adapter_trimmed_reads > 0
#Nç¢±åŸºæ¯”ä¾‹ â‰¤ 2%
#æœ€çŸ­readé•¿åº¦ â‰¥ 50
#å¦‚æœä»¥ä¸Šå…¨éƒ¨æ¡ä»¶éƒ½æ»¡è¶³ï¼Œè¯¥æ ·æœ¬åˆ¤å®šä¸º "PASS"ï¼Œå¦åˆ™ä¸º "FAIL"ã€‚

python3 fastp_qc_summary.py





#########2-Bï¼šå®¿ä¸»DNAå»é™¤#########

######Step 1: æ„å»ºäººç±»å‚è€ƒåŸºå› ç»„ç´¢å¼•#######
 # åˆ›å»ºå­ç›®å½•
    mkdir -p ${db}/kneaddata/ath
    cd ${db}/kneaddata/ath
# æ•°æ®åº“æ¥æºï¼šEnsembl (release 114)
    wget -c https://ftp.ensembl.org/pub/release-114/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz
    mv Homo_sapiens.GRCh38.dna.toplevel.fa.gz human.fa.gz
    # è§£å‹
    gunzip human.fa.gz
    # bowtie2å»ºç´¢å¼•ï¼Œè¾“å…¥æ–‡ä»¶human.faï¼Œè¾“å‡ºæ–‡ä»¶å‰ç¼€tair10ï¼Œ4çº¿ç¨‹2åˆ†
    bowtie2-build -f human.fa tair10 --threads 4

######Step 2: å»å®¿ä¸»#######
# 1. screenè¿è¡Œå»å®¿ä¸»ä¸»æµç¨‹
âœ… å¯åŠ¨ä¸€ä¸ªæ–°ä¼šè¯
#åˆ›å»ºå¹¶è¿›å…¥ä¸€ä¸ªå« mytask çš„ screen ä¼šè¯
screen -S mytask716

# 2. åˆ›å»ºç›®å½•å¹¶æ¿€æ´»ç¯å¢ƒ
mkdir -p temp/hr
conda activate kneaddata

#âœ… 3. åœ¨ä¼šè¯ä¸­è¿è¡Œç¨‹åº
#ç¨‹åºä¼šåœ¨å½“å‰ screen ä¼šè¯ä¸­è¿è¡Œ
#è¾“å…¥æ–‡ä»¶æ˜¯qcæ–‡ä»¶å¤¹ä¸‹è´¨æ§åçš„åºåˆ—{}_1.fastq.gzã€{}_2.fastq.gzï¼›è¾“å‡ºæ–‡ä»¶ä½äºhræ–‡ä»¶å¤¹ä¸‹å»å®¿ä¸»åçš„åºåˆ—{}_paired 1.fastqã€{}_paired 2.fastqï¼Œä»¥åŠå·¥ä½œæ—¥å¿—{}.log
#æ¯æ¬¡å¹¶è¡Œè¿è¡Œ 3 ä¸ªæ ·æœ¬
#-db å‚æ•°åçš„æ•°æ®åº“è·¯å¾„æ›¿æ¢ä¸ºæ‰€ä½¿ç”¨çš„ Bowtie2å»ºç«‹çš„humanç´¢å¼•è·¯å¾„

time tail -n+2 result/metadata.txt | cut -f1 | parallel -j 3 '
  kneaddata \
    -i1 temp/qc/{}_1.fastq.gz \
    -i2 temp/qc/{}_2.fastq.gz \
    -o temp/hr \
    --output-prefix {} \
    --bypass-trim --bypass-trf --reorder \
    --bowtie2-options "--very-sensitive --dovetail" \
    -db /data/gaoyunyun/project/anmiaomiao/kneaddata/ath \
    --remove-intermediate-output -v -t 3 \
    --log temp/hr/{}.log'

#âœ… 4. æš‚æ—¶ç¦»å¼€ screenï¼ˆåå°è¿è¡Œï¼‰
æŒ‰ä¸‹å¿«æ·é”®ï¼š
Ctrl + Aï¼Œç„¶åæŒ‰ D
ä¼šè¯ä¼šè¢«â€œdetachâ€åˆ°åå°ï¼Œç¨‹åºä»ç»§ç»­è¿è¡Œã€‚

#âœ… 5. é‡æ–°è¿›å…¥ä¼šè¯
screen -r mytask716

ğŸ” æŸ¥çœ‹è¾“å‡ºå¹¶é‡å‘½å
# æŸ¥çœ‹å¤§å°ï¼Œ*åŒ¹é…ä»»æ„å¤šä¸ªå­—ç¬¦ï¼Œ?åŒ¹é…ä»»æ„ä¸€ä¸ªå­—ç¬¦
ls -shtr temp/hr/*_paired_?.fastq

#ç®€åŒ–æ”¹å
# Ubuntuç³»ç»Ÿæ”¹å
rename 's/paired_//' temp/hr/*.fastq

ğŸ“Š æ±‡æ€»è´¨æ§ç»“æœ
#è¾“å…¥æ–‡ä»¶ä¸ºhræ–‡ä»¶å¤¹ä¸‹çš„*.logæ–‡ä»¶ï¼›è¾“å‡ºæ–‡ä»¶æ˜¯kneaddata.txtï¼Œå†…å®¹ä¸ºä¸€ä¸ªæ±‡æ€»è¡¨ï¼Œæå–æ¯ä¸ªæ ·æœ¬çš„ reads æ•°é‡ç»Ÿè®¡ä¿¡æ¯
kneaddata_read_count_table --input temp/hr --output temp/kneaddata.txt

# æå–å…³é”®ä¿¡æ¯åˆ—ï¼ˆæ ·æœ¬IDã€è¾“å…¥readsæ•°ã€ä¿ç•™readsæ•°ï¼‰ï¼›è¾“å…¥æ–‡ä»¶æ˜¯kneaddata.txtï¼›è¾“å‡ºæ–‡ä»¶ä¸ºsum.txtï¼Œè®°å½•äº†å»å®¿èˆå‰åreadsæ•°é‡å˜åŒ–
cut -f 1,2,3,5,6 temp/kneaddata.txt | sed 's/_1_kneaddata//' > result/qc/sum.txt

ğŸ§ª é…å¯¹IDæ£€æŸ¥
 paste <(head -n40 temp/hr/`tail -n+2 result/metadata.txt|cut -f1|head -n1`_1.fastq|grep @)    <(head -n40 temp/hr/`tail -n+2 result/metadata.txt|cut -f1|head -n1`_2.fastq|grep @)

ğŸ§¹å¤§æ–‡ä»¶æ¸…ç†ï¼Œé«˜å®¿ä¸»å«é‡æ ·æœ¬å¯èŠ‚çº¦>90%ç©ºé—´
# ä½¿ç”¨å‘½ä»¤çš„ç»å¯¹è·¯å¾„ç¡®ä¿ä½¿ç”¨æ— å‚æ•°çš„å‘½ä»¤
/bin/rm -rf temp/hr/*contam* temp/hr/*unmatched* temp/hr/reformatted* temp/hr/_temp*
ls -l temp/hr/

# ç¡®è®¤å»å®¿ä¸»ç»“æœåï¼Œå¯ä»¥åˆ é™¤è´¨æ§åä¸­é—´æ–‡ä»¶
rm temp/qc/*.fastq.gz





####2-Cï¼šç‰©ç§ç»„æˆåˆ†æå’ŒåŠŸèƒ½æ³¨é‡Š#####

##Step 1: å‡†å¤‡HUMAnNè¾“å…¥æ–‡ä»¶
HUMAnNè¦æ±‚è¾“å…¥æ–‡ä»¶ä¸ºåˆå¹¶çš„åŒç«¯åºåˆ—ï¼Œforå¾ªç¯æ ¹æ®metadata.txtä¸­çš„æ ·æœ¬åæ‰¹é‡åˆå¹¶åŒç«¯åºåˆ—ã€‚æ³¨æ„æ˜Ÿå·(\*)å’Œé—®å·(?)ï¼Œåˆ†åˆ«ä»£è¡¨å¤šä¸ªå’Œå•ä¸ªå­—ç¬¦ã€‚

#åˆ›å»ºæ–‡ä»¶å¤¹
mkdir -p temp/concat

# å°†å»å®¿ä¸»åçš„åŒç«¯åˆå¹¶ä¸ºå•ä¸ªæ–‡ä»¶
    for i in `tail -n+2 result/metadata.txt|cut -f1`;do 
      cat temp/hr/${i}_?.fastq \
      > temp/concat/${i}.fq; done

# æŸ¥çœ‹æ ·å“æ•°é‡å’Œå¤§å°
ls -shl temp/concat/*.fq

##Step 2: HUMAnN 4+ MetaPhlAn 4 ç‰©ç§ç»„æˆåˆ†æå’ŒåŠŸèƒ½æ³¨é‡Š
#åˆ›å»ºæ–‡ä»¶å¤¹
mkdir -p temp/human
mkdir -p temp/metaphlan

#å¯åŠ¨humann4ç¯å¢ƒï¼Œæ£€æŸ¥æ•°æ®åº“é…ç½®
conda activate humann4
humann --version # v4.0.0.alpha.1
humann_config

#å› HUMAnN 4 alpha ç‰ˆæœ¬ä¸å…¼å®¹ MetaPhlAn 4.2 çš„æ–°å‚æ•° --bowtie2outï¼Œç›®å‰åªèƒ½ç‹¬ç«‹è¿è¡Œ MetaPhlAn å¹¶å°†ç»“æœä¼ ç»™ HUMAnN

#å…ˆè¿è¡ŒMetaPhlAn  #v4.2.2
#è¾“å…¥æ–‡ä»¶ï¼štemp/concat/*.fq  åŒç«¯åˆå¹¶åçš„fastqåºåˆ—
#è¾“å‡ºæ–‡ä»¶ï¼š$SAMPLENAME_profile.tsv â€”â€” åŒ…å«ç‰©ç§ç›¸å¯¹ä¸°åº¦åŠè¯»æ•°ç»Ÿè®¡ä¿¡æ¯çš„ MetaPhlAn åˆ†æç»“æœè¡¨ï¼ˆtsvæ ¼å¼ï¼‰
#db_diræŒ‡å®šmetaphlan4æ•°æ®åº“çš„è·¯å¾„

#ï¼ˆå¯é€‰ï¼‰æ‰¹æ¬¡è¿è¡Œ
tail -n+2 result/metadata.txt | cut -f1 | parallel -j 1 'metaphlan temp/concat/{}.fq \
  --input_type fastq \
  --db_dir /data/bjfu/db/metaphlan4/ \
  -x mpa_vOct22_CHOCOPhlAnSGB_202403 \
  --offline \
  -t rel_ab_w_read_stats \
  -o temp/metaphlan/{}_profile.tsv --nproc 8  --verbose'

#ï¼ˆæˆ–ï¼‰å•ä¸ªè¿è¡Œ
metaphlan temp/concat/SRR28210381.fq --input_type fastq \
  --db_dir /data/bjfu/db/metaphlan4/ -x mpa_vOct22_CHOCOPhlAnSGB_202403 \
  --offline -t rel_ab_w_read_stats \
  -o temp/metaphlan/SRR28210381_profile.tsv --nproc 8 --verbose


#å†è¿è¡Œ HUMAnN # v4.0.0.alpha.1
#è¾“å…¥æ–‡ä»¶ï¼štemp/concat/*.fq  åŒç«¯åˆå¹¶åçš„fastqåºåˆ—
          MetaPhlAn è¾“å‡ºç»“æœ$SAMPLENAME_profile.tsv äº¤ç»™ HUMAnNï¼Œç”¨ --taxonomic-profile å‚æ•°ä¼ å…¥
#è¾“å‡ºæ–‡ä»¶ï¼štemp/humann/ ç›®å½•ä¸‹
    *   $SAMPLENAME_0.log â€”â€” è¿è¡Œæ—¥å¿—
    *   $SAMPLENAME_2_genefamilies.tsv â€”â€” åŸºå› å®¶æ—ä¸°åº¦è¡¨ï¼ˆå·²å½’ä¸€åŒ–ä¸ºCPMï¼‰
    *   $SAMPLENAME_3_reactions.tsv â€”â€” ä»£è°¢ååº”ä¸°åº¦è¡¨ï¼ˆå·²å½’ä¸€åŒ–ä¸ºCPMï¼‰
    *   $SAMPLENAME_4_pathabundance.tsv â€”â€” ä»£è°¢é€šè·¯ä¸°åº¦è¡¨ï¼ˆå·²å½’ä¸€åŒ–ä¸ºCPMï¼‰

#ï¼ˆå¯é€‰ï¼‰æ‰¹æ¬¡ï¼ˆ2ä¸ªï¼‰åŒæ—¶è¿è¡Œ
tail -n+2 result/metadata.txt | cut -f1 | parallel -j 2 '
  humann \
    --input temp/concat/{}.fq \
    --output temp/humann/ \
    --threads 16 \
    --taxonomic-profile temp/metaphlan/{}_profile.tsv \
    --verbose'

#ï¼ˆæˆ–ï¼‰å•ä¸ªè¿è¡Œ
humann \
  --input temp/concat/SRR28210381.fq \
  --output temp/humann/ \
  --threads 16 \
  --taxonomic-profile temp/metaphlan/SRR28210381_profile.tsv \
  --verbose

# åˆ é™¤åŒç«¯åˆå¹¶åçš„ä¸´æ—¶æ–‡ä»¶
/bin/rm -rf temp/concat/*

# åˆ é™¤humannè¿è¡Œä¸´æ—¶æ–‡ä»¶
/bin/rm -rf temp/humann/*_humann_temp




####3-Aï¼šç¾¤è½å¤šæ ·æ€§åˆ†æ#####

##Step 1: Kraken2ç‰©ç§æ³¨é‡Š

# å¯åŠ¨kraken2å·¥ä½œç¯å¢ƒ
conda activate /data/bjfu/miniconda3/envs/kraken2.1.3
# è®°å½•è½¯ä»¶ç‰ˆæœ¬
kraken2 --version # 2.1.3
mkdir -p temp/kraken2

#è®¾ç½®ç¯å¢ƒå˜é‡
export db=/data/bjfu/db

#å‚è€ƒæ•°æ®åº“ï¼šæ ¹æ®ç”µè„‘å†…å­˜ç”±å°åˆ°å¤§é€‰æ‹©ä»¥ä¸‹3ä¸ªæ•°æ®åº“â€”pluspf16g(120G)/pluspf(55G)/pluspfp(189G)        #5 million reads ï¼Œ50Gå¤§æ•°æ®åº“è¾ƒ5Gåº“æ³¨é‡Šæ¯”ä¾‹æé«˜10~20%ã€‚
#æœ¬æµç¨‹é€‰æ‹©æ•°æ®åº“ï¼š-db ${db}/kraken2/pluspfp/

#è¾“å…¥æ–‡ä»¶ï¼štemp/hr/{1}_?.fastq å»å®¿ä¸»åçš„æ•°æ®ï¼Œ{1}ä»£è¡¨æ ·æœ¬åï¼›
#è¾“å‡ºç»“æœï¼šæ¯ä¸ªæ ·æœ¬å•ç‹¬è¾“å‡ºï¼Œtemp/kraken2/ä¸­çš„{1}_reportå’Œ{1}_output

#(å¯é€‰) å•æ ·æœ¬æ³¨é‡Š
type=pluspfp 
    i=SRR28210346
    time kraken2 --db ${db}/kraken2/${type}/ \
      --paired temp/hr/${i}_?.fastq \
      --threads 16 --use-names --report-zero-counts \
      --report temp/kraken2/${i}.report \
      --output temp/kraken2/${i}.output

#ï¼ˆæˆ–ï¼‰1æ ·æœ¬16çº¿ç¨‹é€ä¸ªè¿è¡Œç”Ÿæˆreportï¼Œå†…å­˜å¤§ä½†é€Ÿåº¦å¿«ï¼Œä¸å»ºè®®ç”¨å¤šä»»åŠ¡å¹¶è¡Œ
type=pluspfp 
    for i in `tail -n+2 result/metadata.txt | cut -f1`;do
      kraken2 --db ${db}/kraken2/${type} \
      --paired temp/hr/${i}_?.fastq \
      --threads 16 --use-names --report-zero-counts \
      --report temp/kraken2/${i}.report \
      --output temp/kraken2/${i}.output; done

##Step 2: Brackenä¸°åº¦ä¼°è®¡

#Brackenå‚æ•°ç®€ä»‹ï¼š
# -dä¸ºæ•°æ®åº“
# -iä¸ºè¾“å…¥kraken2æŠ¥å‘Šæ–‡ä»¶
# -ræ˜¯è¯»é•¿ï¼Œé€šå¸¸ä¸º150
# -lä¸ºåˆ†ç±»çº§ï¼Œå¯é€‰ç•ŒDã€é—¨Pã€çº²Cã€ç›®Oã€ç§‘Fã€å±Gã€ç§Sçº§åˆ«ä¸°åº¦ä¼°è®¡
# -tæ˜¯é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0ï¼Œè¶Šå¤§è¶Šå¯é ï¼Œä½†å¯ç”¨æ•°æ®è¶Šå°‘
# -oè¾“å‡º Bracken ä¼°è®¡ä¸°åº¦æ–‡ä»¶
# -wè¾“å‡º Bracken æ ·å“ report æ–‡ä»¶

#åˆ›å»ºæ–‡ä»¶å¤¹
mkdir -p temp/bracken
mkdir -p result/kraken2

#å¯¹æ¯ä¸ªæ ·æœ¬çš„ Kraken2.report æ–‡ä»¶ï¼Œåœ¨å¤šä¸ªåˆ†ç±»å­¦å±‚çº§ï¼ˆDã€Pã€Cã€Oã€Fã€Gã€Sï¼‰ä¸Šä½¿ç”¨ Bracken å·¥å…·è¿›è¡Œç‰©ç§ä¸°åº¦é‡ä¼°è®¡ï¼Œç”Ÿæˆæ¯ä¸ªæ ·æœ¬åœ¨æ¯ä¸ªåˆ†ç±»å±‚çº§çš„ Bracken è¾“å‡ºç»“æœ
#æŒ‰åˆ†ç±»çº§åˆ«ï¼ˆD,P,C,O,F,G,Sï¼‰å¾ªç¯é‡æ–°ä¼°è®¡æ¯ä¸ªæ ·å“çš„ä¸°åº¦

#è¾“å…¥æ–‡ä»¶ï¼šmetadata.txt    #æ ·æœ¬ååŠåˆ†ç»„ä¿¡æ¯
         temp/kraken2/{sample}.report    #æ¯ä¸ªæ ·æœ¬çš„Kraken2 ç‰©ç§æ³¨é‡Šæ–‡ä»¶
         ${db}/kraken2/${type}/  Bracken   #åˆ†ç±»ä½¿ç”¨çš„æ•°æ®åº“è·¯å¾„
         /data/gaoyunyun/project/anmiaomiao/filter_feature_table.R    #Rè¿‡æ»¤è„šæœ¬ï¼Œç”¨äºæŒ‰é¢‘ç‡è¿‡æ»¤ä½ä¸°åº¦åˆ†ç±»å•å…ƒ 
#è¾“å‡ºæ–‡ä»¶ï¼štemp/bracken/${i}.${tax}.brkï¼›temp/bracken/${i}.${tax}.report    #æ¯ä¸ªæ ·æœ¬æ¯ä¸ªåˆ†ç±»ç­‰çº§çš„ .brkï¼ˆä¸°åº¦ï¼‰ å’Œ .reportï¼ˆåˆ†ç±»æŠ¥å‘Šï¼‰
          temp/bracken/${i}.count   #æ¯æ ·æœ¬åˆ†ç±»çš„ abundance åˆ—ï¼ˆç¬¬6åˆ—ï¼‰
          result/kraken2/bracken.${tax}.txt     #æ‰€æœ‰æ ·æœ¬åˆå¹¶çš„ç‰©ç§ä¸°åº¦è¡¨ï¼ŒBracken ç»“æœï¼ˆå„ä¸ªåˆ†ç±»ç­‰çº§ï¼‰

#è®¾ç½®ç¯å¢ƒå˜é‡
export db=/data/bjfu/db
type=pluspfp 
readLen=150  # æµ‹åºæ•°æ®é•¿åº¦ï¼Œé€šå¸¸ä¸º150ï¼Œæ—©æœŸæœ‰100/75/50/25

#è¿è¡Œå¾ªç¯è„šæœ¬ï¼ˆæ­¥éª¤æ³¨é‡Šå¦‚ä¸‹ï¼‰
#å¯¹æ¯ä¸ªæ ·æœ¬è¿è¡ŒBrackenï¼Œè¿›è¡Œä¸°åº¦ä¼°ç®—
#ä»Brackenç»“æœæ–‡ä»¶(.brk)ä¸­æå–æå–ç¬¬6åˆ—reads countï¼Œå¹¶æ·»åŠ æ ·æœ¬å
#ä»æœ€åä¸€ä¸ªæ ·æœ¬çš„.brkæ–‡ä»¶ä¸­æå–åˆ†ç±»å­¦åç§°ï¼Œä½œä¸ºåˆå¹¶è¡¨çš„è¡Œå¤´
#åˆå¹¶æ‰€æœ‰æ ·æœ¬çš„è®¡æ•°æ–‡ä»¶ä¸åˆ†ç±»åç§°æ–‡ä»¶ï¼Œç”Ÿæˆå®Œæ•´çš„ä¸°åº¦è¡¨
# ç»Ÿè®¡è¡¨æ ¼è¡Œåˆ—ä¿¡æ¯

for tax in D P C O F G S; do
  echo "### Processing taxonomic level: ${tax} ###"

  for i in $(tail -n+2 result/metadata.txt | cut -f1); do
    bracken -d "${db}/kraken2/${type}/" \
      -i "temp/kraken2/${i}.report" \
      -r "${readLen}" -l "${tax}" -t 0 \
      -o "temp/bracken/${i}.${tax}.brk" \
      -w "temp/bracken/${i}.${tax}.report"
  done

  tail -n+2 result/metadata.txt | cut -f1 | parallel -j 1 \
    "tail -n+2 temp/bracken/{1}.${tax}.brk | LC_ALL=C sort | cut -f6 | sed '1 s/^/{1}\n/' \
    > temp/bracken/{1}.${tax}.count"

  h=$(tail -n1 result/metadata.txt | cut -f1)
  tail -n+2 temp/bracken/${h}.${tax}.brk | LC_ALL=C sort | cut -f1 | sed '1 s/^/Taxonomy\n/' > temp/bracken/0header.${tax}.count

  paste temp/bracken/0header.${tax}.count $(tail -n+2 result/metadata.txt | cut -f1 | awk -v tax="$tax" '{print "temp/bracken/" $0 "." tax ".count"}') \
    > result/kraken2/bracken.${tax}.txt

  csvtk -t stat result/kraken2/bracken.${tax}.txt

done

#æŸ¥çœ‹æ¯ä¸ªåŸå§‹ Bracken è¡¨æ ¼çš„è¡Œåˆ—ç»Ÿè®¡ä¿¡æ¯
csvtk -t stat result/kraken2/bracken.?.txt

#åˆ†æåæ¸…ç†æ¯æ¡åºåˆ—çš„æ³¨é‡Šå¤§æ–‡ä»¶
/bin/rm -rf temp/kraken2/*.output

##Step 3: alphaå¤šæ ·æ€§è®¡ç®—å’Œå¯è§†åŒ–

#alphaå¤šæ ·æ€§è®¡ç®—ï¼š æå–ç§æ°´å¹³ä¸°åº¦è¡¨å¹¶æŠ½å¹³è‡³æœ€å°æµ‹åºé‡ï¼Œè®¡ç®—8ç§alphaå¤šæ ·æ€§æŒ‡æ•°ï¼ˆrichness, chao1, ACE, shannon, simpson, invsimpson, goods_coverage, pielou_eï¼‰
#è¾“å…¥æ–‡ä»¶ï¼šresult/kraken2/bracken.S.txt      #æ‰€æœ‰æ ·æœ¬åˆå¹¶çš„ç§æ°´å¹³ç‰©ç§ä¸°åº¦æ–‡ä»¶ï¼ˆBracken æ ¼å¼ï¼‰
          otutab_rare.R   Rè¯­è¨€è„šæœ¬
#è¾“å‡ºæ–‡ä»¶ï¼šresult/kraken2/bracken.S.alpha   # è¾“å‡ºå¤šæ ·æ€§æŒ‡æ•°ç»“æœ
          result/kraken2/bracken.S.norm   # æŠ½å¹³åçš„ç‰©ç§ä¸°åº¦è¡¨

# å¯åŠ¨kraken2å·¥ä½œç¯å¢ƒ
conda activate /data/bjfu/miniconda3/envs/kraken2.1.3

#è®¾ç½®ç¯å¢ƒå˜é‡
sd=/data/gaoyunyun/project/anmiaomiao

#å‚æ•°è§£æï¼š
-depth=0    #è‡ªåŠ¨æŠ½å¹³åˆ°æœ€å°æµ‹åºé‡
-seed 1       # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯é‡å¤å¯å¤ç°

tax=S
Rscript $sd/otutab_rare.R \
  --input result/kraken2/bracken.${tax}.txt \
  --depth 0 \
  --seed 1 \
  --normalize result/kraken2/bracken.${tax}.norm \
  --output result/kraken2/bracken.${tax}.alpha

##alphaå¤šæ ·æ€§æŒ‰ç»„å¯è§†åŒ–ç»˜åˆ¶ç®±çº¿å›¾

#Rè¯­è¨€è„šæœ¬ï¼šalpha_boxplot.R   Rè¯­è¨€è„šæœ¬
#è¾“å…¥æ–‡ä»¶ï¼š bracken.S.alpha  ç§æ°´å¹³alphaå¤šæ ·æ€§æŒ‡æ•°ç»“æœ
           metadata.txt å„æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šboxplot_alpha.pdf

###Step 4: Beta å¤šæ ·æ€§è·ç¦»çŸ©é˜µè®¡ç®—ã€æŒ‰ç»„å¯è§†åŒ–ç»˜åˆ¶PCoAå›¾

#Rè¯­è¨€è„šæœ¬ï¼šbeta_diversity.R
#è¾“å…¥æ–‡ä»¶ï¼š bracken.S.normï¼šè¾“å…¥ä¸ºç§æ°´å¹³æŠ½å¹³ï¼ˆæ ‡å‡†åŒ–ï¼‰åçš„ä¸°åº¦è¡¨
           metadata.txt å„æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šbray_dis.txtï¼›jaccard_dis.txt  æ ·æœ¬é—´çš„2ç§è·ç¦»çŸ©é˜µ
          PCoA_bray_dis.pdfï¼ŒPCoA_jaccard_dis.pdf        PCoAç»˜å›¾ç»“æœ
 
###Step 5: é—¨ (Phylum)ã€ç§ (Species)æ°´å¹³çš„å¹³å‡ç›¸å¯¹ä¸°åº¦å †å æŸ±çŠ¶å›¾

#Rè¯­è¨€è„šæœ¬ï¼štax_stackplot.R   R è„šæœ¬
#è¾“å…¥æ–‡ä»¶ï¼šbracken.S.txt ï¼›bracken.P.txt é—¨å’Œç§æ°´å¹³çš„ç‰©ç§ä¸°åº¦æ–‡ä»¶ï¼ˆBracken æ ¼å¼ï¼‰
          metadata.txt   æ ·æœ¬åä¸ä¸°åº¦ä¿¡æ¯
                     
#è¾“å‡ºæ–‡ä»¶ï¼šS_stackplot.pdf ï¼›P_stackplot.pdf    å„ç»„å †å æŸ±çŠ¶å›¾
          Phylum_abundance_kruskal_results.csvï¼›species_abundance_kruskal_results.csv    ä¸¤ç»„å¹³å‡ç›¸å¯¹ä¸°åº¦ä¸å·®å¼‚æ˜¾è‘—æ€§ç»Ÿè®¡æ£€éªŒç»“æœ




####3-Bï¼šå·®å¼‚ç‰©ç§åˆ†æ#####

##Step 1: LEfSeå·®å¼‚ç‰©ç§åˆ†æï¼ˆå±æ°´å¹³ï¼‰

#è¾“å…¥æ–‡ä»¶ï¼šresult/kraken2/bracken.G.txt    å±æ°´å¹³ç‰©ç§ä¸°åº¦è¡¨
          result/metadata.txt    æ ·æœ¬åˆ†ç»„ä¿¡æ¯
#ä¸­é—´æ–‡ä»¶ï¼šresult/lefse/lefse.txt   æ•´åˆåˆ†ç»„ä¿¡æ¯åç”¨äºLefSeåˆ†æçš„æ–‡ä»¶ 
          result/lefse/input.in   ç»è½¬åŒ–åLEfSe å†…éƒ¨ä½¿ç”¨çš„è¾“å…¥æ ¼å¼
#LefSeç»“æœè¾“å‡ºï¼šresult/lefse/input.res.txt åˆ†æè¾“å‡ºçš„ç»“æœæ–‡ä»¶ï¼ŒåŒ…æ‹¬äº”åˆ—ï¼Œåˆ†åˆ«æ˜¯ï¼šæ˜¾è‘—å·®å¼‚ç‰©ç§çš„åç§°ï¼›å„ç»„ä¸­è¯¥ç‰©ç§å¹³å‡ä¸°åº¦çš„æœ€å¤§å€¼ï¼ˆlog10ï¼‰ï¼›ç‰©ç§å¯Œé›†çš„ç»„åï¼›LDAå€¼ï¼›Kruskal-Wallisç§©å’Œæ£€éªŒçš„på€¼ï¼Œè‹¥ä¸æ˜¯Biomarkerç”¨â€œ-â€è¡¨ç¤ºã€‚

mkdir -p result/lefse/

#è®¾ç½®è¾“å…¥è·¯å¾„å’Œè¾“å‡ºç›®å½•å˜é‡
input=result/kraken2/bracken.G.txt
outdir=result/lefse

#è®¾ç½®ç¯å¢ƒå˜é‡
result=/data/gaoyunyun/project/anmiaomiao/

#æ„å»ºç¬¦åˆ LEfSe æ ¼å¼çš„è¾“å…¥æ–‡ä»¶ï¼Œä¿®æ”¹æ ·æœ¬åä¸ºç»„å

# æå–æ ·æœ¬è¡Œæ›¿æ¢ä¸ºæ¯ä¸ªæ ·æœ¬ä¸€è¡Œï¼Œç¬¬ä¸€åˆ—åæ”¹ä¸ºSampleID
head -n1 $input | tr '\t' '\n' | sed '1s/.*/SampleID/' > temp/sampleid
head -n3 temp/sampleid

#æŠŠæ–‡ä»¶è½¬æˆ Linux æ ¼å¼
sed -i 's/\r$//' "$result/metadata.txt"

# æ ¹æ® metadata ä¸­æ ·æœ¬ ID æ‰¾åˆ°å¯¹åº” Groupï¼Œè¾“å‡ºä¸€è¡Œï¼ˆæ³¨æ„åŠ ä¸Š Group ä½œä¸ºå¼€å¤´ï¼‰
awk 'BEGIN{OFS=FS="\t"} NR==FNR {a[$1]=$2; next} FNR==1 {printf "Group"} FNR>1 {printf "\t%s", a[$1]} END {printf "\n"}' "$result/metadata.txt" temp/sampleid > groupid
# æŸ¥çœ‹æ˜¯å¦æ­£ç¡®ç”Ÿæˆåˆ†ç»„è¡Œ
cat groupid

# åˆå¹¶åˆ†ç»„è¡Œä¸åŸå§‹æ•°æ®(æ›¿æ¢è¡¨å¤´)
cat groupid <(tail -n+2 $input) > ${outdir}/lefse.txt
head -n3 $result/lefse/lefse.txt

#LEfSeå‘½ä»¤è¡Œåˆ†æï¼Œæ¿€æ´»ç¯å¢ƒ
conda activate /data/bjfu/miniconda3/envs/lefse

# æ ¼å¼è½¬æ¢ä¸ºlefseå†…éƒ¨æ ¼å¼
#å‚æ•°è§£æï¼š-c 1ï¼šç¬¬1åˆ—æ˜¯åˆ†ç»„ä¿¡æ¯ï¼›
          -o 1000000ï¼š å°†æ¯ä¸ªæ ·æœ¬ç‰©ç§æ€»ä¸°åº¦æ ‡å‡†åŒ–ä¸º1000000

    lefse-format_input.py ${outdir}/lefse.txt \
      result/lefse/input.in -c 1 -o 1000000

# è¿è¡Œlefseåˆ†æï¼ˆæ ·æœ¬å¿…é¡»æœ‰é‡å¤å’Œåˆ†ç»„ï¼‰
#LEfSeåˆ†æï¼Œé€šè¿‡ANOVAå’ŒWilcoxonæ£€éªŒç­›é€‰å·®å¼‚æ˜¾è‘—çš„ç‰¹å¾ï¼Œä¸¤ä¸ªæ£€éªŒçš„æ˜¾è‘—æ€§é˜ˆå€¼å‡ä¸ºpå€¼â‰¤0.05ï¼Œéšåå¯¹ç­›é€‰å‡ºçš„ç‰¹å¾è®¡ç®—LDAæ•ˆåº”å€¼ï¼Œ
ä¿ç•™LDAå¾—åˆ†â‰¥2.0çš„ç»“æœï¼Œç¡®ä¿æ‰€è¯†åˆ«çš„å·®å¼‚å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§å’Œç”Ÿç‰©å­¦æ„ä¹‰ã€‚

#å‚æ•°è§£æï¼ˆé€‰æ‹©é»˜è®¤é˜ˆå€¼ï¼‰ï¼š-a (default 0.05)  è¿›è¡Œ ANOVA æ£€éªŒï¼Œä¿ç•™ p å€¼ â‰¤ 0.05 çš„ç‰¹å¾
                        -w (default 0.05) å¯¹é€šè¿‡ ANOVA çš„ç‰¹å¾ï¼Œä½¿ç”¨ Wilcoxon æ£€éªŒï¼Œä¿ç•™ p å€¼ â‰¤ 0.05
                        -l (default 2.0) LDA æ•ˆåº”é‡è¯„åˆ†ï¼Œä¿ç•™ LDA Score â‰¥ 2.0 çš„ç‰¹å¾ä½œä¸ºæ˜¾è‘—å·®å¼‚ç‰¹å¾
                        -r (default LDA) å·®å¼‚ç‰¹å¾åˆ¤å®šæ–¹æ³•ï¼Œä½¿ç”¨çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ è®¡ç®—ç‰¹å¾çš„æ•ˆåº”é‡
                        -s (0 no correctionï¼Œmore strict, default) å¤šé‡æ¯”è¾ƒæ ¡æ­£æ–¹å¼
#ä½¿ç”¨é»˜è®¤å‚æ•°è¿è¡Œ
#run_lefse.py result/lefse/input.in result/lefse/input.res

#ä¸ç­›é€‰ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç»“æœï¼›-a 1 ï¼šANOVAæ£€éªŒ på€¼é˜ˆå€¼è®¾ä¸º1ï¼ˆå³ä¸è¿‡æ»¤ï¼‰ï¼›-w 1 ï¼šWilcoxonæ£€éªŒ på€¼é˜ˆå€¼è®¾ä¸º1ï¼ˆä¸è¿‡æ»¤ï¼‰ï¼›-l 0 ï¼šLDAé˜ˆå€¼è®¾ä¸º0ï¼Œä¿ç•™æ‰€æœ‰LDAå¾—åˆ†çš„ç‰¹å¾
run_lefse.py result/lefse/input.in result/lefse/input.res -a 1 -w 1 -l 0

#æ–‡ä»¶input.resåŠ ä¸Šè¡¨å¤´ï¼Œå¯¼å‡ºä¸ºinput.res.txt
echo -e "Biomarker_Names\tAverage_Abundance(log10)\tEnriched_Groups\tLDA\tKW_Pvalue" > input.res.txt
cat result/lefse/input.res >> input.res.txt


#ç«å±±å›¾ç»˜åˆ¶ï¼ˆæ˜¾è‘—æ€§é˜ˆå€¼ LDA Score â‰¥ 2.0ï¼›på€¼< 0.05ï¼‰
#Rè¯­è¨€è„šæœ¬ï¼šlefse_volcano.R
#è¾“å…¥æ–‡ä»¶ï¼šinput.res.txt    lefseåˆ†æçš„ç»“æœ
          metadata.txt    å„æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šLEfSe_Volcano_Plot.pdf     Lefseåˆ†æç«å±±å›¾ç»˜å›¾ç»“æœ


##Step 2:  MaAsLin2å·®å¼‚ç‰©ç§åˆ†æï¼ˆå±æ°´å¹³ï¼‰

# è¿›è¡Œå·®å¼‚åˆ†æ
#Rè¯­è¨€è„šæœ¬ï¼šcompare_MaAsLin2.R     #è®¾ç½® ID = 1ï¼›HC = 2
#è¾“å…¥æ–‡ä»¶ï¼šbracken.G.txt    å±æ°´å¹³ç‰©ç§ä¸°åº¦è¡¨
          metadata.txt   æ ·æœ¬åˆ†ç»„ä¿¡æ¯
#è¾“å‡ºæ–‡ä»¶ï¼šMaAsLin2_overall_difference.csv    #å¯¹æ¯ä¸€ä¸ªå¾®ç”Ÿç‰©ç‰¹å¾ï¼ˆå±ï¼‰ä¸å˜é‡ï¼ˆGroupï¼‰å›å½’åˆ†æç»“æœæ±‡æ€»è¡¨æ ¼     #Mean1 = HCï¼›Mean2 = ID    MaAsLin2 æ ¹æ®åˆ†ç»„å˜é‡åœ¨Ré‡Œçš„å­—å…¸æ’åºï¼Œé€šå¸¸æŒ‰å­—æ¯é¡ºåº
          MaAsLin2_enriched_depleted.csv    #åŒ…å«ç»„é—´å·®å¼‚æ˜¾è‘—çš„ç‰¹å¾å’Œå¯Œé›†æ–¹å‘ï¼Œç”¨äºä¸‹æ¸¸å¯è§†åŒ–      p < 0.05 ä¸” FC > 1ï¼Œæ ‡è®°ä¸ºdepletedï¼Œåœ¨å¯¹ç…§ç»„ HC ä¸­æ›´é«˜ï¼›p< 0.05 ä¸” FC < 1ï¼Œæ ‡è®°ä¸ºenrichedï¼Œåœ¨ç–¾ç—…ç»„ ID ä¸­æ›´é«˜ï¼›p >= 0.05ï¼Œæ²¡æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚

#å›å½’åˆ†æä¸­ï¼ŒMaAsLin2 çš„è§£é‡Šæ˜¯ï¼Œç”¨ Groupï¼ˆæ•°å€¼å˜é‡ï¼‰æ¥è¿›è¡Œçº¿æ€§æ¨¡å‹å›å½’ï¼ˆæ¯”å¦‚ å› å˜é‡ feature_abundance ~ Group è‡ªå˜é‡ï¼‰
#Group å¢å¤§ï¼šä» ID(1) â†’ HC(2)ï¼›å›å½’ç³»æ•°Î²ï¼ˆBetaï¼‰ç³»æ•° > 0ï¼šè¯´æ˜ abundance éšç€ Group å˜å¤§è€Œå¢åŠ  â†’ åœ¨ HC æ›´é«˜ï¼›FC = 2^Beta > 1ï¼šä¹Ÿä»£è¡¨åœ¨ HC æ›´é«˜ï¼ˆ åœ¨IDä¸­depletedï¼‰

# æ ¹æ®å·®å¼‚åˆ†æç»“æœç»˜åˆ¶ç«å±±å›¾   (æ˜¾è‘—æ€§é˜ˆå€¼FDR< 0.05ï¼›|beta|>0.3ï¼‰
#Rè¯­è¨€è„šæœ¬ï¼šMaAsLin2_volcano.R
#è¾“å…¥æ–‡ä»¶ï¼šMaAsLin2_overall_difference.csv    MaAsLin2 è¾“å‡ºçš„å·®å¼‚åˆ†æç»“æœ
          MaAsLin2_enriched_depleted.csv    å¯Œé›†/è€—ç«­åˆ†ç»„è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šMaAsLin2_volcano.pdf      MaAsLin2åˆ†æç«å±±å›¾ç»˜å›¾ç»“æœ





####3-Cï¼šåŠŸèƒ½å·®å¼‚ä¸é€šè·¯å¯Œé›†åˆ†æ#####

##Step 1: è¯†åˆ«ç»„é—´ä¸°åº¦å·®å¼‚æ˜¾è‘—çš„ MetaCyc é€šè·¯

##é€šè·¯ä¸°åº¦è¡¨åˆå¹¶

#å°†æ‰€æœ‰æ ·æœ¬çš„HUMAnN åŠŸèƒ½é€šè·¯ä¸°åº¦è¡¨ï¼ˆå·²å½’ä¸€åŒ–ä¸ºCPMï¼‰åˆå¹¶æˆä¸€å¼ è¡¨
#è¾“å…¥æ–‡ä»¶ï¼š$SAMPLENAME_4_pathabundance.tsv   å„æ ·æœ¬çš„åŠŸèƒ½é€šè·¯ä¸°åº¦è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šresult/humann/pathabundance.tsv     å°†æ‰€æœ‰æ ·æœ¬çš„é€šè·¯ä¸°åº¦è¡¨åˆå¹¶æˆä¸€å¼ è¡¨
          result/humann/pathabundance_unstratified.tsv   çº¯åŠŸèƒ½ä¸°åº¦è¡¨ï¼ŒåŠŸèƒ½åœ¨æ‰€æœ‰ç‰©ç§ä¸­çš„æ€»ä½“ä¸°åº¦ï¼ˆä¸å«ç‰©ç§ä¿¡æ¯ï¼‰
          result/humann/pathabundance_stratified.tsv    åŒ…å«æ¯ä¸ªèŒå¯¹æ­¤åŠŸèƒ½é€šè·¯ç»„æˆçš„è´¡çŒ®ï¼ŒåŠŸèƒ½å’Œå¯¹åº”ç‰©ç§å…³è”çš„ä¸°åº¦è¡¨

#å¯åŠ¨humann4ç¯å¢ƒ
conda activate humann4

#åˆ›å»ºæ–‡ä»¶å¤¹
mkdir -p result/humann

#åˆå¹¶
humann_join_tables --input temp/humann \
      --file_name pathabundance \
      --output result/humann/pathabundance.tsv
   
# æ ·æœ¬åè°ƒæ•´ï¼šåˆ é™¤åˆ—åå¤šä½™ä¿¡æ¯
#åˆ é™¤åˆ—åä¸­å¤šä½™çš„ _Abundance å­—ç¬¦ä¸²ï¼Œä½¿æ ·æœ¬åæ›´ç®€æ´
    sed -i 's/_Abundance//g' result/humann/pathabundance.tsv
   
# ç»Ÿè®¡å’Œé¢„è§ˆåŠŸèƒ½ä¸°åº¦è¡¨
    csvtk -t stat result/humann/pathabundance.tsv
    head -n5 result/humann/pathabundance.tsv

#åˆ†ç¦»åˆ†å±‚çš„ä¸°åº¦è¡¨ï¼ˆstratifiedï¼‰å’Œéåˆ†å±‚è¡¨ï¼ˆunstratifiedï¼‰
#å°†å¸¦ç‰©ç§åˆ†å±‚ä¿¡æ¯çš„ä¸°åº¦è¡¨æ‹†åˆ†æˆä¸¤éƒ¨åˆ†ï¼š
#åˆ†å±‚è¡¨ï¼ˆstratifiedï¼‰ï¼šåŠŸèƒ½å’Œå¯¹åº”ç‰©ç§å…³è”çš„ä¸°åº¦è¡¨ã€‚
#éåˆ†å±‚è¡¨ï¼ˆunstratifiedï¼‰ï¼šçº¯åŠŸèƒ½ä¸°åº¦è¡¨ï¼ŒåŠŸèƒ½åœ¨æ‰€æœ‰ç‰©ç§ä¸­çš„æ€»ä½“ä¸°åº¦ï¼ˆä¸å«ç‰©ç§ä¿¡æ¯ï¼‰ã€‚

    humann_split_stratified_table \
      --input result/humann/pathabundance.tsv \
      --output result/humann/

##ç»„é—´å·®å¼‚æ¯”è¾ƒ

#ä¸¤æ ·æœ¬æ— æ³•ç»„é—´æ¯”è¾ƒï¼Œåœ¨pclå±‚é¢æ›¿æ¢ä¸ºHMPæ•°æ®è¿›è¡Œç»Ÿè®¡å’Œå¯è§†åŒ–ã€‚

#è¾“å…¥æ•°æ®ï¼šresult/humann/pathabundance_unstratified.tsv  çº¯åŠŸèƒ½ä¸°åº¦è¡¨ 
          result/metadata.txt  æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#ä¸­é—´æ•°æ®ï¼šresult/humann/pathabundance_unstratified.pcl   åŒ…å«åˆ†ç»„ä¿¡æ¯çš„é€šè·¯ä¸°åº¦è¡¨æ ¼æ–‡ä»¶
#è¾“å‡ºç»“æœï¼šresult/humann/associate.txt ç»„é—´æ¯”è¾ƒåªä¿ç•™Q-value â‰¤ 0.05çš„ç»Ÿè®¡ç»“æœè¡¨æ ¼

#åœ¨é€šè·¯ä¸°åº¦ä¸­æ·»åŠ åˆ†ç»„

# æå–æ ·å“åˆ—è¡¨
head -n1 result/humann/pathabundance_unstratified.tsv | sed 's/# Pathway/SampleID/' | tr '\t' '\n' > temp/header

# å»æ‰è¡¨å¤´ SampleIDï¼Œé‡æ–°ç”Ÿæˆ group è¡Œ
awk 'BEGIN{FS=OFS="\t"}
NR==FNR { 
    if (FNR>1) a[$1]=$2;  # è·³è¿‡metadataè¡¨å¤´
    next 
}
FNR>1 {   # è·³è¿‡headeré‡Œçš„SampleID
    if(FNR==2) printf "Group"; 
    printf "\t%s", a[$1]
}
END { print "" }' result/metadata.txt temp/header > temp/group

# åˆæˆæ ·æœ¬ã€åˆ†ç»„+æ•°æ®
    cat <(head -n1 result/humann/pathabundance_unstratified.tsv) temp/group <(tail -n+2 result/humann/pathabundance_unstratified.tsv) \
      > result/humann/pathabundance_unstratified.pcl

head -n3 result/humann/pathabundance_unstratified.pcl | cat -T

#ç»„é—´æ¯”è¾ƒï¼Œç»“æœä¸º4åˆ—çš„æ–‡ä»¶ï¼šé€šè·¯åå­—ï¼Œé€šè·¯åœ¨å„ä¸ªåˆ†ç»„çš„ä¸°åº¦ï¼Œå·®å¼‚P-valueï¼Œæ ¡æ­£åçš„Q-valueã€‚

# å®šä¹‰å˜é‡ï¼šè¾“å…¥æ–‡ä»¶è·¯å¾„
pcl=result/humann/pathabundance_unstratified.pcl

# HUMAnN è¿›è¡Œç»„é—´å·®å¼‚åˆ†æï¼Œé»˜è®¤æ–¹æ³•Kruskal-Wallis æ£€éªŒï¼Œå¹¶è¿›è¡Œ FDRï¼ˆFalse Discovery Rateï¼‰æ ¡æ­£ï¼Œæ˜¾è‘—æ€§é˜ˆå€¼q<0.05

#å‚æ•°è§£æï¼š
--focal-metadatum Groupï¼šGroup åˆ—è¿›è¡Œç»„é—´æ¯”è¾ƒï¼Œéœ€è¦å’Œæä¾›ç»™ humann_associate çš„ .pcl æ–‡ä»¶ç¬¬äºŒåˆ—çš„åˆ†ç»„åˆ—åä¸€è‡´
--focal-type categoricalï¼šè¯´æ˜Group æ˜¯åˆ†ç±»å‹ï¼ˆä¸æ˜¯æ•°å€¼å‹ï¼‰
--last-metadatum Groupï¼šå‘Šè¯‰ç¨‹åºä½ çš„ .pcl æ–‡ä»¶ä¸­ï¼Œå…ƒæ•°æ®çš„æœ€åä¸€åˆ—æ˜¯ Group
--fdr 0.05 ï¼šå¯¹å¤šé‡å‡è®¾æ£€éªŒè¿›è¡Œ FDRï¼ˆFalse Discovery Rateï¼‰æ ¡æ­£ï¼Œå¹¶ç­›é€‰æ ¡æ­£å Q-valueï¼ˆå¤šé‡æ£€éªŒæ ¡æ­£åçš„ p å€¼ï¼‰ â‰¤ 0.05 çš„ç»“æœ

    humann_associate --input ${pcl} \
        --focal-metadatum Group --focal-type categorical \
        --last-metadatum Group --fdr 0.05 \
        --output result/humann/associate.txt
    wc -l result/humann/associate.txt
    head -n5 result/humann/associate.txt

#é€šè·¯å¯Œé›†æ°”æ³¡å›¾å±•ç¤ºæ˜¾è‘—å·®å¼‚é€šè·¯ï¼ˆQ-value â‰¤ 0.05ï¼Œå±•ç¤º|log2FC|æ’åå‰20çš„é€šè·¯ï¼‰
#Rè¯­è¨€è„šæœ¬ï¼šbubble_plot.R
#è¾“å…¥æ–‡ä»¶ï¼šassociate.txt     #ç»„é—´æ¯”è¾ƒåªä¿ç•™Q-value â‰¤ 0.05çš„ç»Ÿè®¡ç»“æœè¡¨æ ¼
#è¾“å‡ºæ–‡ä»¶ï¼šMetaCyc_Plot.pdf       #MetaCyc é€šè·¯å¯Œé›†æ°”æ³¡å›¾ç»˜å›¾ç»“æœ
          df_all_results.csv      #å°†associate.txtå’ŒMetaCyc_pathway_mapè¿›è¡Œåˆå¹¶ï¼Œç»™MetaCycé€šè·¯åç§°æ·»åŠ åˆ†ç±»ä¿¡æ¯
          sig_df_top20.csv     #ç­›é€‰Q-value â‰¤ 0.05ä¸” |log2FC| æ’åå‰20çš„é€šè·¯


##Step 2: æ•°æ®åº“æ³¨é‡ŠåŠŸèƒ½ä¸å·®å¼‚åˆ†æ

#å¯åŠ¨humann4ç¯å¢ƒ
conda activate humann4

#æ•°æ®åº“1ï¼šKEGGæ³¨é‡Š
mkdir -p result/humann/KEGG

#è¾“å…¥æ–‡ä»¶ï¼štemp/humann/${i}_2_genefamilies.tsv â€” æ¯ä¸ªæ ·æœ¬çš„åŸºå› å®¶æ—ä¸°åº¦è¡¨ï¼ˆUniRef90ï¼‰
#è¾“å‡ºæ–‡ä»¶ï¼štemp/humann/${i}_ko.tsv â€” æ¯ä¸ªæ ·æœ¬çš„ KO ä¸°åº¦è¡¨ï¼ˆé€šè¿‡ uniref90_ko åˆ†ç»„æ–‡ä»¶æ³¨é‡Šï¼‰
#å…³é”®å‚æ•°:-g uniref90_ko  æ•°æ®åº“ç±»å‹

for i in `tail -n+2 result/metadata.txt|cut -f1`;do
      humann_regroup_table \
        -i temp/humann/${i}_2_genefamilies.tsv \
        -g uniref90_ko \
        -o temp/humann/${i}_ko.tsv
    done
    
#åˆå¹¶ï¼Œå¹¶ä¿®æ­£æ ·æœ¬å
#è¾“å…¥æ–‡ä»¶ï¼štemp/humann/ ç›®å½•ä¸‹æ‰€æœ‰ä»¥ _ko.tsv ç»“å°¾çš„æ–‡ä»¶ï¼ˆä¸Šæ­¥ç”Ÿæˆçš„ï¼‰
#è¾“å‡ºæ–‡ä»¶ï¼šresult/humann/KEGG/ko.tsv â€” åˆå¹¶åçš„æ‰€æœ‰æ ·æœ¬ KO ä¸°åº¦çŸ©é˜µï¼ˆæ¯åˆ—ä¸€ä¸ªæ ·æœ¬ï¼‰

    humann_join_tables \
      --input temp/humann/ \
      --file_name ko \
      --output result/humann/KEGG/ko.tsv

#æŸ¥çœ‹åˆå¹¶åè¡¨æ ¼çš„æœ€åå‡ è¡Œ
tail result/humann/KEGG/ko.tsv

# åˆ†å±‚ç»“æœï¼šåŠŸèƒ½å’Œå¯¹åº”ç‰©ç§è¡¨(stratified)å’ŒåŠŸèƒ½ç»„æˆè¡¨(unstratified)
#è¾“å…¥ï¼šresult/humann/KEGG/ko.tsv â€” è¿‡æ»¤åå«åˆ†å±‚åŠŸèƒ½çš„ KO ä¸°åº¦è¡¨
#è¾“å‡ºï¼šåœ¨ result/humann/KEGG/ ç›®å½•ç”Ÿæˆï¼š
      ko_stratified.tsv â€” å«ç‰©ç§æ³¨é‡Šçš„åˆ†å±‚ KO è¡¨
      ko_unstratified.tsv â€” çº¯ KO åŠŸèƒ½æ€»ä¸°åº¦è¡¨ï¼ˆæ— ç‰©ç§æ³¨é‡Šï¼‰
    
humann_split_stratified_table \
      --input result/humann/KEGG/ko.tsv \
      --output result/humann/KEGG/ 

# æŸ¥çœ‹è¡Œæ•°ç¡®è®¤ç»“æœ
wc -l result/humann/KEGG/ko*
    
#KO åŠŸèƒ½æ±‡æ€»åˆ° KEGG L1-L4 å±‚çº§
#è¾“å…¥æ–‡ä»¶ï¼šresult/humann/KEGG/ko_unstratified.tsv â€” æ— ç‰©ç§åˆ†å±‚çš„ KO ä¸°åº¦è¡¨ï¼ˆä»ä¸Šä¸€æ­¥ç”Ÿæˆï¼‰
          ${db}/KO1-4.txt â€” KO åˆ° KEGG è·¯å¾„å±‚çº§ï¼ˆL1-L4ï¼‰çš„æ˜ å°„æ–‡ä»¶ï¼Œæ ¼å¼ä¸€èˆ¬æ˜¯ KOå· å¯¹åº” å„çº§è·¯å¾„åç§°
#è¾“å‡ºæ–‡ä»¶ï¼šKEGG.KoDescription.raw.txt  #æŒ‰ç…§ KO åŠŸèƒ½æè¿°ï¼ˆL4ï¼‰æ±‡æ€»çš„ä¸°åº¦æ•°æ®
          KEGG.Pathway.raw.txt            #æŒ‰ç…§å®Œæ•´ KEGG Pathwayï¼ˆL3ï¼‰æ±‡æ€»çš„ä¸°åº¦æ•°æ®
          KEGG.PathwayL1.raw.txt        #KEGG ä¸€çº§è·¯å¾„ï¼ˆå¦‚ Metabolism, Genetic Information Processing ç­‰ï¼‰æ±‡æ€»çš„ä¸°åº¦æ•°æ®
          KEGG.PathwayL2.raw.txt        #KEGG äºŒçº§è·¯å¾„ï¼ˆå¦‚ Carbohydrate metabolism, Energy metabolism ç­‰ï¼‰æ±‡æ€»çš„ä¸°åº¦æ•°æ®

#åœ¨é“¾æ¥ä¸‹ä¸‹è½½è„šæœ¬,å¹¶ç²˜åˆ°è·¯å¾„/data/gaoyunyun/project/anmiaomiaoä¸‹ï¼ˆhttps://github.com/YongxinLiu/EasyMicrobiome/blob/master/script/summarizeAbundance.pyï¼‰
#åœ¨é“¾æ¥ä¸‹ä¸‹è½½KO1-4.txtï¼Œå¹¶ç²˜åˆ°è·¯å¾„/data/gaoyunyun/project/anmiaomiaoä¸‹ï¼ˆhttps://github.com/YongxinLiu/EasyMicrobiome/blob/master/kegg/KO1-4.txtï¼‰

#è®¾ç½®ç¯å¢ƒå˜é‡
export db=/data/gaoyunyun/project/anmiaomiao

python ${db}/summarizeAbundance.py \
  -i result/humann/KEGG/ko_unstratified.tsv \
  -m ${db}/KO1-4.txt \
  -c 2,3,4,5 -s ',+,+,+' -n raw \
  -o result/humann/KEGG/

# æŸ¥çœ‹è¡Œæ•°ç¡®è®¤ç»“æœ   
wc -l result/humann/KEGG*

##ç»„é—´å·®å¼‚æ¯”è¾ƒ
#å·®å¼‚åˆ†ææ–¹æ³•1ï¼šKruskal-Wallis æ£€éªŒ
#ä¸¤æ ·æœ¬æ— æ³•ç»„é—´æ¯”è¾ƒï¼Œåœ¨pclå±‚é¢æ›¿æ¢ä¸ºHMPæ•°æ®è¿›è¡Œç»Ÿè®¡å’Œå¯è§†åŒ–ã€‚

#è¾“å…¥æ•°æ®ï¼šresult/humann/KEGG/ko_unstratified.tsv  çº¯ KO åŠŸèƒ½ä¸°åº¦è¡¨ 
          result/metadata.txt  æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#ä¸­é—´æ•°æ®ï¼šresult/humann/KEGG/ko_unstratified.pcl   åŒ…å«åˆ†ç»„ä¿¡æ¯çš„é€šè·¯ä¸°åº¦è¡¨æ ¼æ–‡ä»¶
#è¾“å‡ºç»“æœï¼šresult/humann/KEGG/associate_ko.txt  ç»„é—´æ¯”è¾ƒåªä¿ç•™Q-value â‰¤ 0.05çš„ç»Ÿè®¡ç»“æœè¡¨æ ¼

#åœ¨é€šè·¯ä¸°åº¦ä¸­æ·»åŠ åˆ†ç»„
# æå–æ ·å“åˆ—è¡¨
head -n1 result/humann/KEGG/ko_unstratified.tsv | sed 's/# Gene Family HUMAnN v4.0.0.alpha.1 Adjusted CPMs/SampleID/' | tr '\t' '\n' > temp/header

# å»æ‰è¡¨å¤´ SampleIDï¼Œé‡æ–°ç”Ÿæˆ group è¡Œ
awk 'BEGIN{FS=OFS="\t"}
NR==FNR { 
    if (FNR>1) a[$1]=$2;  # è·³è¿‡metadataè¡¨å¤´
    next 
}
FNR>1 {   # è·³è¿‡headeré‡Œçš„SampleID
    if(FNR==2) printf "Group"; 
    printf "\t%s", a[$1]
}
END { print "" }' result/metadata.txt temp/header > temp/group

# åˆæˆæ ·æœ¬ã€åˆ†ç»„+æ•°æ®
    cat <(head -n1 result/humann/KEGG/ko_unstratified.tsv) temp/group <(tail -n+2 result/humann/KEGG/ko_unstratified.tsv) \
      > result/humann/KEGG/ko_unstratified.pcl

head -n3 result/humann/KEGG/ko_unstratified.pcl | cat -T

#ç»„é—´æ¯”è¾ƒï¼Œç»“æœä¸º4åˆ—çš„æ–‡ä»¶ï¼šé€šè·¯åå­—ï¼Œé€šè·¯åœ¨å„ä¸ªåˆ†ç»„çš„ä¸°åº¦ï¼Œå·®å¼‚P-valueï¼Œæ ¡æ­£åçš„Q-valueã€‚

# å®šä¹‰å˜é‡ï¼šè¾“å…¥æ–‡ä»¶è·¯å¾„
pcl=result/humann/KEGG/ko_unstratified.pcl

# HUMAnN è¿›è¡Œç»„é—´å·®å¼‚åˆ†æï¼Œé»˜è®¤æ–¹æ³•Kruskal-Wallis æ£€éªŒï¼Œå¹¶è¿›è¡Œ FDRï¼ˆFalse Discovery Rateï¼‰æ ¡æ­£ï¼Œæ˜¾è‘—æ€§é˜ˆå€¼q<0.05

#å‚æ•°è§£æï¼š
--focal-metadatum Groupï¼šGroup åˆ—è¿›è¡Œç»„é—´æ¯”è¾ƒï¼Œéœ€è¦å’Œæä¾›ç»™ humann_associate çš„ .pcl æ–‡ä»¶ç¬¬äºŒåˆ—çš„åˆ†ç»„åˆ—åä¸€è‡´
--focal-type categoricalï¼šè¯´æ˜Group æ˜¯åˆ†ç±»å‹ï¼ˆä¸æ˜¯æ•°å€¼å‹ï¼‰
--last-metadatum Groupï¼šå‘Šè¯‰ç¨‹åºä½ çš„ .pcl æ–‡ä»¶ä¸­ï¼Œå…ƒæ•°æ®çš„æœ€åä¸€åˆ—æ˜¯ Group
--fdr 0.05 ï¼šå¯¹å¤šé‡å‡è®¾æ£€éªŒè¿›è¡Œ FDRï¼ˆFalse Discovery Rateï¼‰æ ¡æ­£ï¼Œå¹¶ç­›é€‰æ ¡æ­£å Q-valueï¼ˆå¤šé‡æ£€éªŒæ ¡æ­£åçš„ p å€¼ï¼‰ â‰¤ 0.05 çš„ç»“æœ

    humann_associate --input ${pcl} \
        --focal-metadatum Group --focal-type categorical \
        --last-metadatum Group --fdr 0.05 \
        --output result/humann/KEGG/associate_ko.txt
    wc -l result/humann/KEGG/associate_ko.txt
    head -n5 result/humann/KEGG/associate_ko.txt

#å·®å¼‚åˆ†ææ–¹æ³•2ï¼š
#MaAsLin2 è¿›è¡Œç»„é—´å·®å¼‚åˆ†æï¼Œè¿›è¡Œ FDRæ ¡æ­£ï¼Œæ˜¾è‘—æ€§é˜ˆå€¼q<0.05
#Rè¯­è¨€è„šæœ¬ï¼ško_compare_MaAsLin2.R
#è¾“å…¥æ–‡ä»¶ï¼ško_unstratified.tsv     #çº¯ KO åŠŸèƒ½ä¸°åº¦è¡¨
          metadata.txt  æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼ško_MaAsLin2_overall_difference.csv     #MaAsLin2åˆ†æè¾“å‡ºçš„KEGGé€šè·¯å·®å¼‚åˆ†æç»“æœ
          ko_MaAsLin2_enriched_depleted.csv     #MaAsLin2åˆ†æè¾“å‡ºçš„KEGGé€šè·¯å¯Œé›†/è€—ç«­åˆ†ç»„è¡¨

#æ•°æ®åº“2ï¼šeggNOGæ³¨é‡Š

mkdir -p result/humann/eggnog

#è¾“å…¥æ–‡ä»¶ï¼štemp/humann/${i}_2_genefamilies.tsv â€” æ¯ä¸ªæ ·æœ¬çš„åŸºå› å®¶æ—ä¸°åº¦è¡¨ï¼ˆUniRef90ï¼‰
#è¾“å‡ºæ–‡ä»¶ï¼štemp/humann/${i}_eggnog.tsv â€” æ¯ä¸ªæ ·æœ¬çš„ eggnogæ³¨é‡Šè¡¨
#å…³é”®å‚æ•°:-g uniref90_eggnog   æ•°æ®åº“ç±»å‹

for i in `tail -n+2 result/metadata.txt|cut -f1`;do
      humann_regroup_table \
        -i temp/humann/${i}_2_genefamilies.tsv \
        -g uniref90_eggnog \
        -o temp/humann/${i}_eggnog.tsv
    done

#åˆå¹¶ï¼Œå¹¶ä¿®æ­£æ ·æœ¬å
#è¾“å…¥æ–‡ä»¶ï¼štemp/humann/ ç›®å½•ä¸‹æ‰€æœ‰ä»¥ _eggnog.tsv ç»“å°¾çš„æ–‡ä»¶ï¼ˆå¦‚ä¸Šæ­¥ç”Ÿæˆçš„ï¼‰
#è¾“å‡ºæ–‡ä»¶ï¼šresult/humann/eggnog/eggnog.tsv â€” åˆå¹¶åçš„æ‰€æœ‰æ ·æœ¬eggNOGä¸°åº¦çŸ©é˜µï¼ˆæ¯åˆ—ä¸€ä¸ªæ ·æœ¬ï¼‰

    humann_join_tables \
      --input temp/humann/ \
      --file_name eggnog \
      --output result/humann/eggnog/eggnog.tsv

#æŸ¥çœ‹åˆå¹¶åè¡¨æ ¼çš„æœ€åå‡ è¡Œ
tail result/humann/eggnog/eggnog.tsv

# åˆ†å±‚ç»“æœï¼šåŠŸèƒ½å’Œå¯¹åº”ç‰©ç§è¡¨(stratified)å’ŒåŠŸèƒ½ç»„æˆè¡¨(unstratified)
#è¾“å…¥ï¼šresult/humann/eggnog/eggnog.tsv â€” åˆå¹¶åçš„æ‰€æœ‰æ ·æœ¬eggNOGä¸°åº¦çŸ©é˜µï¼ˆæ¯åˆ—ä¸€ä¸ªæ ·æœ¬ï¼‰
#è¾“å‡ºï¼šåœ¨ result/humann/eggnog/ ç›®å½•ç”Ÿæˆï¼š
      eggnog_stratified.tsv â€” å«ç‰©ç§æ³¨é‡Šçš„åˆ†å±‚eggNOG è¡¨
      eggnog_unstratified.tsv â€” çº¯eggNOG åŠŸèƒ½æ€»ä¸°åº¦è¡¨ï¼ˆæ— ç‰©ç§ï¼‰
    
humann_split_stratified_table \
      --input result/humann/eggnog/eggnog.tsv \
      --output result/humann/eggnog/
    
# æŸ¥çœ‹è¡Œæ•°ç¡®è®¤ç»“æœ
wc -l result/humann/eggnog/eggnog*

#å·®å¼‚åˆ†æï¼š
#MaAsLin2 è¿›è¡Œç»„é—´å·®å¼‚åˆ†æï¼Œè¿›è¡Œ FDRæ ¡æ­£ï¼Œæ˜¾è‘—æ€§é˜ˆå€¼q<0.05
#Rè¯­è¨€è„šæœ¬ï¼šeggnog_compare_MaAsLin2.R
#è¾“å…¥æ–‡ä»¶ï¼šeggnog_unstratified.tsv     #çº¯ KO åŠŸèƒ½ä¸°åº¦è¡¨
          metadata.txt  æ ·æœ¬åˆ†ç»„ä¿¡æ¯è¡¨
#è¾“å‡ºæ–‡ä»¶ï¼šeggnog_MaAsLin2_overall_difference.csv    #MaAsLin2åˆ†æè¾“å‡ºçš„COGé€šè·¯å·®å¼‚åˆ†æç»“æœ
          eggnog_MaAsLin2_enriched_depleted.csv     #MaAsLin2åˆ†æè¾“å‡ºçš„COGé€šè·¯å¯Œé›†/è€—ç«­åˆ†ç»„è¡¨


#æ•°æ®åº“3ï¼šCAZyæ³¨é‡Šå’ŒCARDæ³¨é‡Š

#1. ä½¿ç”¨MEGAHITå¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œç»„è£…
# è¾“å…¥æ–‡ä»¶ï¼šå»å®¿ä¸»åçš„åŒç«¯åºåˆ—temp/hr/{}_1.fastqï¼›temp/hr/{}_2.fastq 
# è¾“å‡ºæ–‡ä»¶ï¼šç»„è£…åçš„åºåˆ— result/megahit/final.contigs.fa

#æ¿€æ´»ç¯å¢ƒ
conda activate /data/bjfu/miniconda3/envs/metawrap

#è®¾ç½®å…¨å±€çº¿ç¨‹ã€å¹¶è¡Œä»»åŠ¡æ•°  p:threadsçº¿ç¨‹æ•°ï¼›jobä»»åŠ¡æ•°
    p=4
    j=2

# å¿«é€Ÿè¯»å–æ ·æœ¬ä¿¡æ¯metadata.txtï¼Œç”Ÿæˆæ ·æœ¬IDåˆ—è¡¨å†ç»§ç»­ç¼–å†™

**ç»„è£…Assemble**
#å•æ ·æœ¬å¹¶è¡Œç»„è£…ï¼›æ”¯æŒä¸­æ–­ç»§ç»­è¿è¡Œï¼Œ18s6hï¼Œ
    
time tail -n+2 result/metadata.txt | cut -f1 | parallel -j ${j} \
  "metawrap assembly -m 800 -t ${p} --megahit \
   -1 temp/hr/{}_1.fastq -2 temp/hr/{}_2.fastq \
   -o temp/megahit/{}"

# æ‰¹é‡è¿è¡ŒQUASTè¯„ä¼°
    for i in `tail -n+2 result/metadata.txt | cut -f1`;do
        quast.py result/megahit/${i}/final.contigs.fa \
            -o result/megahit/${i}/quast -t 8
    done

#2. åŸºå› é¢„æµ‹ã€å»å†—ä½™å’Œå®šé‡Gene prediction, cluster & quantitfy

#æ¿€æ´»ç¯å¢ƒ
conda activate megahit

### metaProdigalåŸºå› é¢„æµ‹Gene prediction

# è¾“å…¥æ–‡ä»¶ï¼šç»„è£…çš„åºåˆ— result/megahit/final.contigs.fa
# è¾“å‡ºæ–‡ä»¶ï¼šprodigalé¢„æµ‹çš„åŸºå› åºåˆ— temp/prodigal/gene.fa

mkdir -p temp/prodigal

#prodigalçš„metaæ¨¡å¼é¢„æµ‹åŸºå› ï¼Œ>å’Œ2>&1è®°å½•åˆ†æè¿‡ç¨‹è‡³gene.logã€‚1.8G1.5h
    time prodigal -i result/megahit/final.contigs.fa \
        -d temp/prodigal/gene.fa \
        -o temp/prodigal/gene.gff \
        -p meta -f gff > temp/prodigal/gene.log 2>&1 
   
# æŸ¥çœ‹æ—¥å¿—æ˜¯å¦è¿è¡Œå®Œæˆï¼Œæœ‰æ— é”™è¯¯
    tail temp/prodigal/gene.log
    
# ç»Ÿè®¡åŸºå› æ•°é‡,6G18s3M
    seqkit stat temp/prodigal/gene.fa 
    
# ç»Ÿè®¡å®Œæ•´åŸºå› æ•°é‡ï¼Œæ•°æ®é‡å¤§å¯åªç”¨å®Œæ•´åŸºå› éƒ¨åˆ†
grep -c 'partial=00' temp/prodigal/gene.fa 

# æå–å®Œæ•´åŸºå› (å®Œæ•´ç‰‡æ®µè·å¾—çš„åŸºå› å…¨ä¸ºå®Œæ•´ï¼Œå¦‚æˆç¯çš„ç»†èŒåŸºå› ç»„)
    grep 'partial=00' temp/prodigal/gene.fa | cut -f1 -d ' '| sed 's/>//' > temp/prodigal/full_length.id
    seqkit grep -n -r -p "partial=00" temp/prodigal/gene.fa > temp/prodigal/full_length.fa
    seqkit stat temp/prodigal/full_length.fa

#3. cd-hitåŸºå› èšç±»/å»å†—ä½™cluster & redundancy

# è¾“å…¥æ–‡ä»¶ï¼šprodigalé¢„æµ‹çš„åŸºå› åºåˆ— temp/prodigal/gene.fa
# è¾“å‡ºæ–‡ä»¶ï¼šå»å†—ä½™åçš„åŸºå› å’Œè›‹ç™½åºåˆ—ï¼šresult/NR/nucleotide.fa, result/NR/protein.fa

mkdir -p result/NR

# aSè¦†ç›–åº¦ï¼Œcç›¸ä¼¼åº¦ï¼ŒGå±€éƒ¨æ¯”å¯¹ï¼Œgæœ€ä¼˜è§£ï¼ŒTå¤šçº¿ç¨‹ï¼ŒMå†…å­˜0ä¸é™åˆ¶
# 2ä¸‡åŸºå› 2mï¼Œ3M384p15mï¼Œ2åƒä¸‡éœ€è¦2000hï¼Œå¤šçº¿ç¨‹å¯åŠ é€Ÿ
    cd-hit-est -i temp/prodigal/gene.fa \
        -o result/NR/nucleotide.fa \
        -aS 0.9 -c 0.95 -G 0 -g 0 -T 0 -M 0
# ç»Ÿè®¡éå†—ä½™åŸºå› æ•°é‡ï¼Œå•æ¬¡æ‹¼æ¥ç»“æœæ•°é‡ä¸‹é™ä¸å¤§ï¼Œå¦‚3M-2Mï¼Œå¤šæ‰¹æ‹¼æ¥å†—ä½™åº¦é«˜
    grep -c '>' result/NR/nucleotide.fa
# ç¿»è¯‘æ ¸é…¸ä¸ºå¯¹åº”è›‹ç™½åºåˆ—, --trimå»é™¤ç»“å°¾çš„*
    seqkit translate --trim result/NR/nucleotide.fa \
        > result/NR/protein.fa 
# ä¸¤æ‰¹æ•°æ®å»å†—ä½™ä½¿ç”¨cd-hit-est-2dåŠ é€Ÿï¼Œè§é™„å½•

#4. salmonåŸºå› å®šé‡quantitfy

# è¾“å…¥æ–‡ä»¶ï¼šå»å†—ä½™åçš„åŸºå› åºåˆ—ï¼šresult/NR/nucleotide.fa
# è¾“å‡ºæ–‡ä»¶ï¼šSalmonå®šé‡ï¼šresult/salmon/gene.count, gene.TPM

mkdir -p temp/salmon
salmon -v # 1.8.0

# å»ºç´¢å¼•, -tåºåˆ—, -i ç´¢å¼•ï¼Œ10s
    salmon index -t result/NR/nucleotide.fa \
      -p 3 -i temp/salmon/index 

# å®šé‡ï¼Œlæ–‡åº“ç±»å‹è‡ªåŠ¨é€‰æ‹©ï¼Œpçº¿ç¨‹ï¼Œ--metaå®åŸºå› ç»„

###æ‰‹åŠ¨è·‘ä¸€ä¸ªæ ·æœ¬C1
    i=C1
    salmon quant -i temp/salmon/index -l A -p 8 --meta \
        -1 temp/hr/${i}_1.fastq -2 temp/hr/${i}_2.fastq \
        -o temp/salmon/${i}.quant

###æ‰¹é‡è·‘æ‰€æœ‰æ ·æœ¬ï¼ˆæ¯”å¦‚ SRR å¼€å¤´çš„ IDï¼‰
    # 2ä¸ªä»»åŠ¡å¹¶è¡Œ, 18s30m
    time tail -n+2 result/metadata.txt | cut -f1 | parallel -j 2 \
      "salmon quant -i temp/salmon/index -l A -p 3 --meta \
        -1 temp/hr/{1}_1.fastq -2 temp/hr/{1}_2.fastq \
        -o temp/salmon/{1}.quant"

# åˆå¹¶
    mkdir -p result/salmon
    salmon quantmerge --quants temp/salmon/*.quant \
        -o result/salmon/gene.TPM
    salmon quantmerge --quants temp/salmon/*.quant \
        --column NumReads -o result/salmon/gene.count
    sed -i '1 s/.quant//g' result/salmon/gene.*

# é¢„è§ˆç»“æœè¡¨æ ¼
    head -n3 result/salmon/gene.*

#5. åŠŸèƒ½åŸºå› æ³¨é‡ŠFunctional gene annotation

### CAZyç¢³æ°´åŒ–åˆç‰©é…¶æ³¨é‡Š+ ä¸°åº¦ç»Ÿè®¡
# è¾“å…¥æ–‡ä»¶ï¼šresult/NR/protein.fa    ä¸Šä¸€æ­¥é¢„æµ‹çš„è›‹ç™½åºåˆ— 
           result/salmon/gene.TPM       å„åŸºå› åœ¨æ ·æœ¬ä¸­çš„ TPM è¡¨è¾¾ä¸°åº¦
#è¾“å‡ºæ–‡ä»¶ï¼štemp/dbcan3/gene_diamond.f6   Diamond æ¯”å¯¹ç»“æœï¼ˆBLAST tab æ ¼å¼ï¼Œè®°å½•æ¯ä¸ªåŸºå› çš„æœ€ä½³ CAZy å®¶æ—åŒ¹é…ï¼‰
          temp/dbcan3/gene.list         ç­›é€‰åçš„åŸºå›  â†’ CAZy å®¶æ—æ˜ å°„è¡¨ï¼ˆæŒ‰ E-value è¿‡æ»¤ï¼‰
          result/dbcan3/TPM.CAZy.raw.txt       æ¯ä¸ª CAZy å®¶æ—åœ¨å„æ ·æœ¬ä¸­çš„ TPM ä¸°åº¦
          result/dbcan3/TPM.CAZy.raw.spf       è½¬æ¢ä¸º STAMP .spf æ ¼å¼ï¼ˆå¸¦åŠŸèƒ½æè¿°ï¼Œå¯ç›´æ¥å¯¼å…¥ STAMP åšå·®å¼‚åˆ†æï¼‰

# æ¯”å¯¹CAZyæ•°æ®åº“, ç”¨æ—¶2~18m
mkdir -p temp/dbcan3 result/dbcan3

# --sensitiveæ…¢10å€ï¼Œdbcan3eå€¼ä¸º1e-102
    time diamond blastp \
      --db /data/bjfu/db/dbcan3/CAZyDB \
      --query result/NR/protein.fa \
      --threads 2 -e 1e-102 --outfmt 6 --max-target-seqs 1 --quiet \
      --out temp/dbcan3/gene_diamond.f6
    wc -l temp/dbcan3/gene_diamond.f6

# æå–åŸºå› ä¸dbcanåˆ†ç±»å¯¹åº”è¡¨ï¼ŒæŒ‰Evalueå€¼è¿‡æ»¤ï¼Œæ¨è1e-102
    perl format_dbcan2list.pl \
      -i temp/dbcan3/gene_diamond.f6 \
      -e 1e-102 \
      -o temp/dbcan3/gene.list 
# æŒ‰å¯¹åº”è¡¨ç´¯è®¡ä¸°åº¦ï¼Œä¾èµ–
    python3 summarizeAbundance.py \
      -i result/salmon/gene.TPM \
      -m temp/dbcan3/gene.list \
      -c 2 -s ',' -n raw --dropkeycolumn \
      -o result/dbcan3/TPM
    
# æ·»åŠ æ³¨é‡Šç”ŸæˆSTAMPçš„spfæ ¼å¼
#åœ¨é“¾æ¥ä¸‹ä¸‹è½½CAZy_description.txtï¼Œå¹¶ç²˜åˆ°è·¯å¾„ä¸‹https://github.com/YongxinLiu/EasyMicrobiome/blob/master/dbcan2/CAZy_description.txt
    awk 'BEGIN{FS=OFS="\t"} NR==FNR{a[$1]=$2} NR>FNR{print a[$1],$0}' \
       ${db}/data/gaoyunyun/project/anmiaomiao/CAZy_description.txt \
      result/dbcan3/TPM.CAZy.raw.txt | \
      sed 's/^\t/Unannotated\t/' \
      > result/dbcan3/TPM.CAZy.raw.spf
    head result/dbcan3/TPM.CAZy.raw.spf

# æ£€æŸ¥æœªæ³¨é‡Šæ•°é‡ï¼Œæœ‰åˆ™éœ€è¦æ£€æŸ¥åŸå› 
grep 'Unannotated' result/dbcan3/TPM.CAZy.raw.spf|wc -l


### CARDè€è¯åŸºå› æ³¨é‡Š(RGI)+ ä¸°åº¦ç»Ÿè®¡
#è¾“å…¥æ–‡ä»¶ï¼šresult/NR/protein.fa    ä¸Šä¸€æ­¥é¢„æµ‹çš„è›‹ç™½åºåˆ—
          result/salmon/gene.TPM    Salmon è¾“å‡ºçš„æ¯ä¸ªåŸºå› åœ¨å„æ ·æœ¬çš„ TPM
#è¾“å‡ºæ–‡ä»¶ï¼šresult/card/TPM.CARD.raw.txtï¼šCARD ç±»åˆ«åœ¨å„æ ·æœ¬çš„ä¸°åº¦çŸ©é˜µ
          result/card/TPM.CARD.raw.spfï¼šSTAMP å¯ç”¨çš„ä¸°åº¦è¡¨ï¼ˆå¸¦æè¿°ï¼‰

# åˆ›å»ºç»“æœç›®å½•
mkdir -p temp/card result/card

# å¯åŠ¨ RGI ç¯å¢ƒå¹¶æŸ¥çœ‹ç‰ˆæœ¬
conda activate /data/bjfu/miniconda3/envs/rgi
rgi main -v   # 6.0.3

# ç®€åŒ–è›‹ç™½ IDï¼ˆå»æ‰ç©ºæ ¼é¿å…è§£æå‡ºé”™ï¼‰
cut -f 1 -d ' ' result/NR/protein.fa > temp/protein.fa
grep '>' temp/protein.fa | head -n 3  # æ£€æŸ¥æ˜¯å¦æˆåŠŸ

# RGI æ¯”å¯¹è›‹ç™½è‡³ CARD æ•°æ®åº“
# æ³¨æ„ï¼šç¬¬ä¸€æ¬¡ä½¿ç”¨ RGI æˆ–æ•°æ®åº“æ›´æ–°åéœ€æ‰§è¡Œï¼š
# rgi load -i $db/card/card.json --card_annotation $db/card/card.fasta
time rgi main \
    -i temp/protein.fa \
    -t protein \
    -n 9 \
    -a DIAMOND \
    --include_loose \
    --clean \
    -o result/card/protein

# æå–åŸºå› ä¸ CARD åˆ†ç±»å¯¹åº”è¡¨
# è¿™é‡Œä»¥ Drug Class ä½œä¸ºåˆ†ç±»æ ‡ç­¾
awk -F "\t" 'NR>1 {print $1"\t"$10}' result/card/protein.txt \
    > temp/card/gene.list

# æŒ‰ CARD åˆ†ç±»ç´¯è®¡ä¸°åº¦ï¼ˆä¾èµ– summarizeAbundance.pyï¼‰
python3 summarizeAbundance.py \
    -i result/salmon/gene.TPM \
    -m temp/card/gene.list \
    -c 2 -s ',' -n raw --dropkeycolumn \
    -o result/card/TPM

# æ·»åŠ æ³¨é‡Šå¹¶ç”Ÿæˆ STAMP çš„ SPF æ ¼å¼
# åœ¨æ­¤é“¾æ¥ä¸‹ä¸‹è½½CARD_description.txtï¼Œå¹¶ç²˜åˆ°è·¯å¾„ä¸‹https://github.com/YongxinLiu/EasyMicrobiome/blob/master/card/CARD_description.txt
awk 'BEGIN{FS=OFS="\t"} NR==FNR{a[$1]=$2} NR>FNR{print a[$1],$0}' \
    ${db}/data/gaoyunyun/project/anmiaomiao/CARD_description.txt \
    result/card/TPM.CARD.raw.txt | \
    sed 's/^\t/Unannotated\t/' \
    > result/card/TPM.CARD.raw.spf

head result/card/TPM.CARD.raw.spf

# æ£€æŸ¥æœªæ³¨é‡Šæ•°é‡
grep 'Unannotated' result/card/TPM.CARD.raw.spf | wc -l
